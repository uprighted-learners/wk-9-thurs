# Import required libraries
import pandas as pd  # Main library for data manipulation and analysis
# Load the three datasets using pd.read_csv()
# This function reads CSV files and converts them into pandas DataFrames
customers = pd.read_csv('/Users/conorshields/Documents/customers_wk9_thurs.csv')
products = pd.read_csv('/Users/conorshields/Documents/products_wk9_thurs.csv')
sales = pd.read_csv('/Users/conorshields/Documents/sales_wk9_thurs.csv')
# Display basic information about what we've loaded
# len() gives us the number of rows in each DataFrame
print(f"‚úÖ Successfully loaded:")
print(f"   - {len(customers)} customers")      # Total number of customer records
print(f"   - {len(products)} products")        # Total number of products in catalog
print(f"   - {len(sales)} sales transactions") # Total number of sales transactions

# Display the first few rows of each dataset to understand the structure
# .head(n) shows the first n rows of a DataFrame - useful for data exploration
print(f"\nüëÄ First few rows of each dataset:")
print(f"\nCustomers:")
print(customers.head(3))  # Show first 3 rows of customer data
print(f"\nProducts:")
print(products.head(3))   # Show first 3 rows of product data
print(f"\nSales:")
print(sales.head(3))      # Show first 3 rows of sales data



# =============================================================================
# PART 1: DATETIME OPERATIONS
# =============================================================================
# DateTime operations are crucial for time-based analysis in business data
# We'll convert text dates to proper datetime objects and extract useful components

print("\n" + "=" * 60)
print("PART 1: DATETIME OPERATIONS")
print("=" * 60)

print("\nüïê 1.1 Converting and Working with Dates")

# Convert date columns from strings to pandas datetime objects
# pd.to_datetime() is the main function for converting various date formats
# Once converted, we can perform date arithmetic and extract components
print("Converting date columns to datetime...")
customers['registration_date'] = pd.to_datetime(customers['registration_date'])
products['launch_date'] = pd.to_datetime(products['launch_date'])
sales['transaction_date'] = pd.to_datetime(sales['transaction_date'])

print("‚úÖ All date columns converted successfully")


# Extract useful components from datetime objects using the .dt accessor
# The .dt accessor gives us access to datetime-specific methods and properties
print("\nExtracting datetime components...")
sales['year'] = sales['transaction_date'].dt.year           # Extract year (2022, 2023, etc.)
sales['month'] = sales['transaction_date'].dt.month         # Extract month number (1-12)
sales['day_of_week'] = sales['transaction_date'].dt.dayofweek  # Day of week (Monday=0, Sunday=6)
sales['day_name'] = sales['transaction_date'].dt.day_name()    # Day name as text (Monday, Tuesday, etc.)
print("‚úÖ Extracted: year, month, day of week, and day name")


# Find the date range of our sales data by using min() and max()
# This helps us understand the time span our analysis covers
sales_start = sales['transaction_date'].min()  # Earliest transaction date
sales_end = sales['transaction_date'].max()    # Latest transaction date
print(f"\nüìÖ Sales data date range:")
print(f"   Earliest sale: {sales_start.strftime('%B %d, %Y')}")  # Format: January 15, 2022
print(f"   Latest sale: {sales_end.strftime('%B %d, %Y')}")      # Format: March 05, 2024
print(f"   Total days: {(sales_end - sales_start).days} days")   # Calculate difference in days

print("\nüîç 1.2 Basic Time Analysis")



# Find the busiest day of the week by counting transactions
# .value_counts() counts occurrences of each unique value
day_counts = sales['day_name'].value_counts()  # Count transactions for each day name
busiest_day = day_counts.index[0]             # Get the day with most transactions (first in sorted list)
busiest_count = day_counts.iloc[0]            # Get the count for that day
print(f"Busiest day of the week: {busiest_day} ({busiest_count} transactions)")

# Display all days ranked by transaction count for complete picture
print(f"\nAll days ranked by transaction count:")
for day, count in day_counts.items():  # Iterate through day names and their counts
    print(f"   {day}: {count} transactions")


# Find the month with the most transactions
month_counts = sales['month'].value_counts().sort_index()  # Count by month, then sort by month number
busiest_month_num = sales['month'].value_counts().idxmax()  # Get month number with highest count
busiest_month_count = sales['month'].value_counts().max()   # Get the actual count

# Create a dictionary to convert month numbers to readable names
# This makes our output more user-friendly
month_names = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June',
               7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'}

print(f"\nBusiest month: {month_names[busiest_month_num]} ({busiest_month_count} transactions)")



print(f"\nTransactions by month:")
for month_num, count in month_counts.items():              # Iterate through months and counts
    print(f"   {month_names[month_num]}: {count} transactions")  # Use month names instead of numbers



# Count sales by year to see yearly trends
year_counts = sales['year'].value_counts().sort_index()    # Count transactions by year, sort chronologically
print(f"\nSales by year:")
for year, count in year_counts.items():
    print(f"   {year}: {count} transactions")



# Count sales by year to see yearly trends
year_counts = sales['year'].value_counts().sort_index()    # Count transactions by year, sort chronologically
print(f"\nSales by year:")
for year, count in year_counts.items():
    print(f"   {year}: {count} transactions")



# =============================================================================
# PART 2: GROUPBY AND AGGREGATION
# =============================================================================
# GroupBy operations allow us to split data into groups and perform calculations
# on each group separately. This is essential for analyzing patterns and trends.

print("\n" + "=" * 60)
print("PART 2: GROUPBY AND AGGREGATION")
print("=" * 60)

print("\nüõçÔ∏è 2.1 Product Analysis")


# Group products by category and calculate average price for each category
# .groupby() splits the data into groups based on the 'category' column
# .mean() calculates the average for each group
# .round(2) rounds to 2 decimal places for currency formatting
# .sort_values(ascending=False) sorts from highest to lowest price
category_avg_price = products.groupby('category')['price'].mean().round(2).sort_values(ascending=False)
print("Average price by product category:")
for category, avg_price in category_avg_price.items():  # Loop through each category and its average price
    print(f"   {category}: ${avg_price}")               # Format with dollar sign


# Count how many products exist in each category
# .value_counts() counts occurrences of each unique category
category_counts = products['category'].value_counts()
print(f"\nNumber of products in each category:")
for category, count in category_counts.items():
    print(f"   {category}: {count} products")



# Group customers by state and calculate average age
# This shows us the demographic profile of customers in different regions
state_avg_age = customers.groupby('state')['age'].mean().round(1).sort_values(ascending=False)
print("Average customer age by state:")
for state, avg_age in state_avg_age.items():
    print(f"   {state}: {avg_age} years")


# Calculate total spending per customer (Customer Lifetime Value)
# Group sales by customer_id and sum their total_amount for each customer
# This gives us each customer's total spending across all their purchases
customer_spending = sales.groupby('customer_id')['total_amount'].sum().sort_values(ascending=False)
print(f"\nCustomer spending statistics:")
print(f"   Average spending per customer: ${customer_spending.mean():.2f}")  # Mean of all customer totals
print(f"   Highest spending customer: ${customer_spending.max():.2f}")       # Maximum customer spending
print(f"   Lowest spending customer: ${customer_spending.min():.2f}")        # Minimum customer spending


# Find customers with the most purchases (transaction frequency)
# .groupby().size() counts the number of transactions per customer
# This is different from sum() - it counts rows, not values
customer_purchase_counts = sales.groupby('customer_id').size().sort_values(ascending=False)
top_buyer_id = customer_purchase_counts.index[0]        # Customer ID with most purchases
top_buyer_purchases = customer_purchase_counts.iloc[0]  # Number of purchases by top customer
print(f"\nCustomer with most purchases: Customer #{top_buyer_id} ({top_buyer_purchases} purchases)")



# Show top 5 customers by number of purchases
print(f"\nTop 5 customers by number of purchases:")
for customer_id, purchase_count in customer_purchase_counts.head().items():  # .head() gets top 5
    print(f"   Customer #{customer_id}: {purchase_count} purchases")

print("\nüìà 2.3 Sales Analysis")


# Calculate total sales revenue by month
# Group sales by month and sum the total_amount for each month
monthly_revenue = sales.groupby('month')['total_amount'].sum().sort_values(ascending=False)
print("Total revenue by month:")
for month_num, revenue in monthly_revenue.items():
    print(f"   {month_names[month_num]}: ${revenue:,.2f}")  # :,.2f formats with commas and 2 decimals



# Calculate average transaction amount by day of week
# This shows us if people spend more on certain days
daily_avg_amount = sales.groupby('day_name')['total_amount'].mean().round(2)
# Reorder by actual day order (Monday first) instead of alphabetical
day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
daily_avg_amount = daily_avg_amount.reindex(day_order)  # Reorder according to day_order list




